# Installations :

install.packages("naniar")
install.packages("visdat")
install.packages("corrplot")
install.packages("mapview")
install.packages('caTools')
install.packages("quantable")
install.packages("fastDummies")
install.packages("ISLR")
install.packages("glmnet")
install.packages("caret")
install.packages("Metrics")

# Imports :

library(naniar)
library(visdat)
library(ggplot2)
library(RColorBrewer)
library(corrplot)
library(mapview)
library(tidyverse)
library(sf)
library(mapview)
library(caTools)
library('fastDummies')
library(ISLR)
library(glmnet)
library(tidyr)
library(plyr)
library(readr)
library(dplyr)
library(caret)
library(ggplot2)
library(repr)
library(xgboost) 
library(caret) 
library(glmnet)
library(Metrics)

# In 2050, the city of Seattle has set itself the goal of achieving a level of carbon neutrality.
# In order not to bear new additional costs, like the readings of the campaigns carried out in 2015 and 2016, the city needs predictions for its buildings not intended for housing.

##### I Understanding Of The Dataset : #####

#### A- Load Data And Exploration : ####

### 1- Loading csv file "Building 2016" : ###

building2016 <- read.csv("/Users/sylvaincarlevato/PRISONNER666/2016_Building_Energy_Benchmarking.csv")

### 2- Visualization of the "Building 2016" Dataframe : ###

head(building2016)

### 3- Names of Columns in the Dataset : ###

names(building2016)

### 4- Number of Rows and Columns of the Initial Dataset : ###

dim(building2016)

# Observations : There are 3376 Rows and 46 Columns in the Initial Dataframe.

### 5- Types of Qualitative and Quantitative Variables of the Initial Dataset : ###

str(building2016)

### 6- Quantification of Duplicate Values of the Initial Dataset : ###

sum(duplicated(building2016))

# Observations : The dataset contains 0 duplicate values.

### 7- Statistical Informations of the Initial Dataset : ###

summary(building2016)

#### B- Missing Values : ####

### 1- Location of NaNs in the Dataset : ###

is.na(building2016)

### 2- Sum of NaNs in Dataset : ###

sum(is.na(building2016)) 

# Observations : The dataset contains 11259 NaNs.

### 3- List of Variables and their Types of the Entire Dataset : ###

vis_dat(building2016)

### 4- Percentage of Missing Values : ###

vis_miss(building2016)

### 5- Other Visualizations of Missing Dataset Values : ###

gg_miss_var(building2016)

#### C- Understanding Targets : ####

### ALPHA - TotalGHGEmissions : ###

### 1- Visualization of the First 10 Values of the TotalGHGEmissions Column : ###

ghge <- building2016 %>% select(starts_with("TotalGHGEmissions"))

ghge[1:10,]

### 2- Descriptive Statistics of the TotalGHGEmissions Column : ###

summary(ghge)

### BETA - SiteEnergyUseWN(kBtu) : ###

### 1- Visualization of the First 10 Values of the SiteEnergyUseWN(kBtu) Column : ###

energ <- building2016 %>% select(starts_with("SiteEnergyUseWN.kBtu."))

energ[1:10,]

### 2- Descriptive Statistics of the SiteEnergyUseWN(kBtu) Column : ###

summary(energ)

#### D- Selection of the type of dwellings : ####

### 1- Type of Buildings to choose : ### 

building2016 %>% select(BuildingType)

### 2- Basic Piechart of Dwellings : ###

pie(table(building2016$BuildingType), main = "Type of Habitations")

### 3- Selection of Buildings not intended for Housing : ###

building2016nonres <- filter(building2016, BuildingType == "NonResidential")

building2016nonres

#### E- Feature Engineering : ####

### 1- Creating "BuildingAge" Column : ###

building2016nonres$BuildingAge <- building2016nonres$DataYear - building2016nonres$YearBuilt

building2016nonres$BuildingAge

building2016nonres

### 2- Moving Column BuildingAge : ###

building2016nonres <- building2016nonres %>% relocate(BuildingAge, .before = BuildingType)

building2016nonres

### 3- New Variables : ###

building2016nonres$GFAPerBuilding <- round((building2016nonres$PropertyGFATotal / building2016nonres$NumberofBuildings),3)

building2016nonres$GFAPerFloor <- round((building2016nonres$PropertyGFATotal / building2016nonres$NumberofFloors),3)

building2016nonres$EnergyUsePerFloor <- round((building2016nonres$SiteEnergyUseWN.kBtu. / building2016nonres$NumberofFloors),3)

building2016nonres$EnergyUsePerBuilding <- round((building2016nonres$SiteEnergyUseWN.kBtu. / building2016nonres$NumberofBuildings),3)

building2016nonres$TotalGHGEmissionsPerFloor <- round((building2016nonres$TotalGHGEmissions / building2016nonres$NumberofFloors), 3)

building2016nonres$GHGEmissionsIntensityPerFloor <- round((building2016nonres$GHGEmissionsIntensity / building2016nonres$NumberofFloors), 3)

### 4- Replacement of NaN by 0 : ###

building2016nonres[is.na(building2016nonres)] <- 0

sum(is.na(building2016nonres)) 

##### II Multivariate Analysis : #####

require(plyr)
require(dplyr)

#### A- Univariate Analysis : ####

### 1- Type of Habitations : ###

building2016 %>% 
  group_by(BuildingType) %>% 
  dplyr:: summarise(count = n()) %>% 
  ggplot(aes(x = reorder(BuildingType,(-count)), y = count)) + 
  geom_bar(stat = 'identity') +
  xlab("BuildingType") + ggtitle("Type of Habitations") 

# Observations : The Most Important Type Of Habitations is "Non Residential" Type and "Multifamily LR (1-4). 
# For my study, I am interested in Non Residential Type.

### 2- Number Of Floors : ###

building2016 %>% 
  group_by(NumberofFloors) %>% 
  dplyr:: summarise(count = n()) %>% 
  ggplot(aes(x = reorder(NumberofFloors,(-count)), y = count)) + 
  geom_bar(stat = 'identity') +
  xlab("NumberofFloors") + ggtitle("Number Of Floors") 

# Observations : The Most Important Number Of Floors for a Dwelling is "3".

#### B- Bivariate Analysis : ####

### 1- Number of Buildings / Building Type : ###

ggplot(building2016, aes(x=NumberofBuildings, y=BuildingType)) + geom_boxplot() + xlim(0,10)

# Observations : Multifamily HR(10+) has the most important spread of values for the Number Of Buildings.

### 2-  Number of Floors / Building Type : ###

ggplot(building2016, aes(x=NumberofFloors, y=BuildingType)) + geom_boxplot() + xlim(0,50)

# Observations : Multifamily HR(10+) has the most important spread of values for the Number Of Floors. 

### 3- GHGEmissionsIntensity / Building Type : ###

ggplot(building2016, aes(x=GHGEmissionsIntensity, y=BuildingType)) + geom_boxplot() + xlim(0,20)

# Observations : NonResidential COS has the most important spread of values for the GHGEmissionsIntensity.

### 4- TotalGHGEmissions / Building Type : ###

ggplot(building2016, aes(x=TotalGHGEmissions, y=BuildingType)) + geom_boxplot() + xlim(0,500)

# Observations : Multifamily HR(10+) has the most important spread of values for the TotalGHGEmissions.

### 5- SiteEnergyUseWN.kBtu. / Building Type : ###

building2016$SiteEnergyUseWN.kBtu. <- as.integer(building2016$SiteEnergyUseWN.kBtu.)

ggplot(building2016, aes(x= SiteEnergyUseWN.kBtu., y=BuildingType)) + geom_boxplot() + xlim(0,5000000)

# Observations : Multifamily MR (10+) has the most important spread of values for the SiteEnergyUseWN.kBtu.

### 6- SiteEnergyUse.kBtu. / Building Type : ###

building2016$SiteEnergyUse.kBtu. <- as.integer(building2016$SiteEnergyUse.kBtu.)

ggplot(building2016, aes(x= SiteEnergyUse.kBtu., y=BuildingType)) + geom_boxplot() + xlim(0,5000000)

# Observations : Multifamily MR (10+) has the most important spread of values for the SiteEnergyUse.kBtu.

#### C- Multivariate Analysis : ####

### Correlation Matrix : ###

corrdataset <- building2016nonres %>% select(NumberofFloors, NumberofBuildings, PropertyGFATotal, PropertyGFAParking, SiteEUI.kBtu.sf., SiteEnergyUse.kBtu., SiteEnergyUseWN.kBtu., TotalGHGEmissions, GHGEmissionsIntensity)

mcor <- cor(corrdataset, method = c("pearson", "kendall", "spearman"))

corrplot(mcor, type="upper", order="hclust", tl.col="black", tl.srt=45)

# Observations : Variables like Number Of Buildings or Number Of Floors have a real impact on Variables like SiteEnergyUse.kBtu. or TotalGHGEmissions.

#### D- GEOLOCALISATION : ####

### 1- TOTALGHGEmissions : ###

mapCO2 <- building2016nonres %>% select(TotalGHGEmissions, Latitude, Longitude)

mapCO2

mapview(mapCO2, xcol = "Longitude", ycol = "Latitude", crs = 4269, grid = FALSE)

### 2- Energy : ###

mapENERGY <- building2016nonres %>% select(SiteEnergyUseWN.kBtu., Latitude, Longitude)

mapENERGY

mapview(mapENERGY, xcol = "Longitude", ycol = "Latitude",crs = 4269, grid = FALSE)

##### III MACHINE LEARNING : #####

#### A- Ridge Regression : ####

# Ridge regression is a method we can use to fit a regression model when multicollinearity is present in the data.

# Least squares regression tries to find coefficient estimates that minimize the sum of squared residuals (RSS) :
  
# RSS = Σ(yi – ŷi)2 

# Where:
# Σ: A greek symbol that means sum
# yi: The actual response value for the ith observation
# ŷi: The predicted response value based on the multiple linear regression model

# Conversely, ridge regression seeks to minimize the following :
  
# RSS + λΣβj2 where j ranges from 1 to p predictor variables and λ ≥ 0.

# This second term in the equation is known as a shrinkage penalty. In ridge regression, we select a value for λ that produces the lowest possible test MSE (mean squared error).

# We’ll use the R built-in dataset called building2016nonres. We’ll use TotalGHGEmissions and SiteEnergyUseWN.kBtu. as the response variable and the following variables as the predictors :
  
# 'GHGEmissionsIntensityPerFloor', 'TotalGHGEmissionsPerFloor', 'EnergyUsePerBuilding', 'EnergyUsePerFloor', 'GFAPerFloor', 'GFAPerBuilding', 'GHGEmissionsIntensity','SiteEnergyUseWN.kBtu.','SiteEnergyUse.kBtu.','ThirdLargestPropertyUseTypeGFA','SecondLargestPropertyUseTypeGFA','LargestPropertyUseTypeGFA', 'NaturalGas.kBtu.','NaturalGas.therms.','Electricity.kBtu.','Electricity.kWh.','PropertyGFABuilding.s.','PropertyGFAParking','PropertyGFATotal','NumberofFloors','Number ofBuildings'.

# To perform ridge regression, we’ll use functions from the glmnet package. This package requires the response variable to be a vector and the set of predictor variables to be of the class data.matrix.

### 1- TARGET : TotalGHGEmissions : ###

glimpse(building2016nonres)

# Define Response Variable :

y_target_CO2 <- building2016nonres$TotalGHGEmissions

# Define Matrix of Predictor Variables :

X_matrix_CO2 <- data.matrix(building2016nonres[, c('GHGEmissionsIntensityPerFloor', 'TotalGHGEmissionsPerFloor', 'EnergyUsePerBuilding', 'EnergyUsePerFloor', 'GFAPerFloor', 'GFAPerBuilding', 'GHGEmissionsIntensity','SiteEnergyUseWN.kBtu.','SiteEnergyUse.kBtu.','ThirdLargestPropertyUseTypeGFA','SecondLargestPropertyUseTypeGFA','LargestPropertyUseTypeGFA',
                                        'NaturalGas.kBtu.','NaturalGas.therms.','Electricity.kBtu.','Electricity.kWh.','PropertyGFABuilding.s.','PropertyGFAParking','PropertyGFATotal','NumberofFloors','NumberofBuildings')])

# Fit Ridge Regression Model :

# Next, we’ll use the glmnet() function to fit the ridge regression model and specify alpha=0.

# Note that setting alpha equal to 1 is equivalent to using Lasso Regression and setting alpha to some value between 0 and 1 is equivalent to using an elastic net.

# Also note that ridge regression requires the data to be standardized such that each predictor variable has a mean of 0 and a standard deviation of 1.

# Fortunately glmnet() automatically performs this standardization for you. If you happened to already standardize the variables, you can specify standardize=False.

model <- glmnet(X_matrix_CO2, y_target_CO2, alpha = 0)

# View Summary of Model :

summary(model)

# Choose an Optimal Value for Lambda :

# Next, we’ll identify the lambda value that produces the lowest test mean squared error (MSE) by using k-fold cross-validation.

# Fortunately, glmnet has the function cv.glmnet() that automatically performs k-fold cross validation using k = 10 folds.

# Perform k-fold Cross-Validation to find Optimal Lambda Value :

cv_model <- cv.glmnet(X_matrix_CO2, y_target_CO2, alpha = 0)

# Find Optimal Lambda Value that minimizes Test MSE :

best_lambda <- cv_model$lambda.min

best_lambda

# Observations : The lambda value that minimizes the test MSE turns out to be 51.

# Produce Plot of Test MSE by Lambda Value :

plot(cv_model) 

# Analyze Final Model :

# Lastly, we can analyze the final model produced by the optimal lambda value.

# We can use the following code to obtain the coefficient estimates for this model :

# Find Coefficients of Best Model :

best_model <- glmnet(X_matrix_CO2, y_target_CO2, alpha = 0, lambda = best_lambda)

coef(best_model)

# We can also produce a Trace plot to visualize how the coefficient estimates changed as a result of increasing lambda :

# Produce Ridge Trace Plot :

plot(model, xvar = "lambda")

# Lastly, we can calculate the R-squared of the model on the training data :

# Use Fitted Best Model to make Predictions :

y_predicted <- predict(model, s = best_lambda, newx = X_matrix_CO2)

# Find SST and SSE :

sst <- sum((y_target_CO2 - mean(y_target_CO2))^2)

sse <- sum((y_predicted - y_target_CO2)^2)

# Find R-Squared :

rsq <- 1 - sse/sst

rsq

# The R-squared turns out to be 0,91. That is, the best model was able to explain 91.99% of the variation in the response values of the training data.

# Find MAE :

mae(actual = y_target_CO2, predicted = y_predicted)

# Find MSE :

mse(actual = y_target_CO2, predicted = y_predicted)

# Find RMSE :

rmse(actual = y_target_CO2, predicted = y_predicted)

### 2- TARGET : SiteEnergyUseWN.kBtu. : ###

glimpse(building2016nonres)

# Define response variable :

y_target_NRJ <- building2016nonres$SiteEnergyUseWN.kBtu.

# Define matrix of predictor variables :

X_matrix_NRJ <- data.matrix(building2016nonres[, c('GHGEmissionsIntensityPerFloor', 'TotalGHGEmissionsPerFloor', 'EnergyUsePerBuilding', 'EnergyUsePerFloor', 'GFAPerFloor', 'GFAPerBuilding', 'GHGEmissionsIntensity','TotalGHGEmissions','ThirdLargestPropertyUseTypeGFA','SecondLargestPropertyUseTypeGFA','LargestPropertyUseTypeGFA',
                                        'NaturalGas.kBtu.','NaturalGas.therms.','Electricity.kBtu.','Electricity.kWh.','PropertyGFABuilding.s.','PropertyGFAParking','PropertyGFATotal','NumberofFloors','NumberofBuildings')])
                                        
# Fit Ridge Regression Model :

model <- glmnet(X_matrix_NRJ, y_target_NRJ, alpha = 0)

# View Summary of Model :

summary(model)

# Perform k-fold Cross-Validation to find Optimal Lambda Value :

cv_model <- cv.glmnet(X_matrix_NRJ, y_target_NRJ, alpha = 0)

# Find Optimal Lambda Value that minimizes Test MSE :

best_lambda <- cv_model$lambda.min

best_lambda

# Produce Plot of Test MSE by Lambda Value :

plot(cv_model) 

# Find Coefficients of Best Model :

best_model <- glmnet(X_matrix_NRJ, y_target_NRJ, alpha = 0, lambda = best_lambda)

coef(best_model)

# Produce Ridge Trace Plot :

plot(model, xvar = "lambda")

# Use Fitted Best Model to make Predictions :

y_predicted <- predict(model, s = best_lambda, newx = X_matrix_NRJ)

# Find SST and SSE :

sst <- sum((y_target_NRJ - mean(y_target_NRJ))^2)

sse <- sum((y_predicted - y_target_NRJ)^2)

# Find R-Squared :

rsq <- 1 - sse/sst

rsq

# Find MAE :

mae(actual = y_target_NRJ, predicted = y_predicted)

# Find MSE :

mse(actual = y_target_NRJ, predicted = y_predicted)

# Find RMSE :

rmse(actual = y_target_NRJ, predicted = y_predicted)

#### B- XG BOOST : ####

### 1- TARGET : TotalGHGEmissions : ###

glimpse(building2016nonres)

# Exploration of the Data :

head(building2016nonres)

# Statistical Summary of the Data Columns :

summary(building2016nonres)

# Number of Lines and Columns of the Dataset ;

dim(building2016nonres)

# Train and Test Data :

parts = createDataPartition(building2016nonres$TotalGHGEmissions, p = .8, list = F)

train = building2016nonres[parts, ]

test = building2016nonres[-parts, ]

# Define Predictor and Response Variables in Training Set :

train_x = data.matrix(train[, c('GHGEmissionsIntensityPerFloor', 'TotalGHGEmissionsPerFloor', 'EnergyUsePerBuilding', 'EnergyUsePerFloor', 'GFAPerFloor', 'GFAPerBuilding', 'GHGEmissionsIntensity','TotalGHGEmissions','ThirdLargestPropertyUseTypeGFA','SecondLargestPropertyUseTypeGFA','LargestPropertyUseTypeGFA',
                                'NaturalGas.kBtu.','NaturalGas.therms.','Electricity.kBtu.','Electricity.kWh.','PropertyGFABuilding.s.','PropertyGFAParking','PropertyGFATotal','NumberofFloors','NumberofBuildings')])

train_y = train$TotalGHGEmissions

# Define Predictor and Response Variables in Testing Set :

test_x = data.matrix(test[, c('GHGEmissionsIntensityPerFloor', 'TotalGHGEmissionsPerFloor', 'EnergyUsePerBuilding', 'EnergyUsePerFloor', 'GFAPerFloor', 'GFAPerBuilding', 'GHGEmissionsIntensity','TotalGHGEmissions','ThirdLargestPropertyUseTypeGFA','SecondLargestPropertyUseTypeGFA','LargestPropertyUseTypeGFA',
                              'NaturalGas.kBtu.','NaturalGas.therms.','Electricity.kBtu.','Electricity.kWh.','PropertyGFABuilding.s.','PropertyGFAParking','PropertyGFATotal','NumberofFloors','NumberofBuildings')])

test_y = test$TotalGHGEmissions

# Replace Inf and NaN by 0 :

train_x[is.infinite(train_x)] <- 0
train_x[is.na(train_x)] <- 0
train_y[is.infinite(train_y)] <- 0
train_y[is.na(train_y)] <- 0

test_x[is.infinite(test_x)] <- 0
test_x[is.na(test_x)] <- 0
test_y[is.infinite(test_y)] <- 0
test_y[is.na(test_y)] <- 0

# Define Final Training and Testing Sets :

xgb_train = xgb.DMatrix(data = train_x, label = train_y)

xgb_test = xgb.DMatrix(data = test_x, label = test_y)

# Define Watchlist :

watchlist = list(train=xgb_train, test=xgb_test)

# Fit XGBoost Model and display Training and Testing Data at each round :

model = xgb.train(data = xgb_train, max.depth = 3, watchlist=watchlist, nrounds = 100)

# Define Final Model :

model_xgboost = xgboost(data = xgb_train, max.depth = 3, nrounds = 86, verbose = 0)

# Use Model to make Predictions on Test Data :

pred_y = predict(model_xgboost, xgb_test)

# Metrics :

# MSE :

mean((test_y - pred_y)^2) 

# MAE :

caret::MAE(test_y, pred_y) 

# RMSE :

caret::RMSE(test_y, pred_y) 

### 2- TARGET : SiteEnergyUseWN.kBtu. : ###

glimpse(building2016nonres)

# Exploration of the Data :

head(building2016nonres)

# Statistical Summary of the Data Columns :

summary(building2016nonres)

# Number of Lines and Columns of the Dataset ;

dim(building2016nonres)

# Train and Test Data :

parts = createDataPartition(building2016nonres$SiteEnergyUseWN.kBtu., p = .8, list = F)

train = building2016nonres[parts, ]

test = building2016nonres[-parts, ]

# Define Predictor and Response Variables in Training Set :

train_x = data.matrix(train[, c('GHGEmissionsIntensityPerFloor', 'TotalGHGEmissionsPerFloor', 'EnergyUsePerBuilding', 'EnergyUsePerFloor', 'GFAPerFloor', 'GFAPerBuilding', 'GHGEmissionsIntensity','TotalGHGEmissions','ThirdLargestPropertyUseTypeGFA','SecondLargestPropertyUseTypeGFA','LargestPropertyUseTypeGFA',
                                'NaturalGas.kBtu.','NaturalGas.therms.','Electricity.kBtu.','Electricity.kWh.','PropertyGFABuilding.s.','PropertyGFAParking','PropertyGFATotal','NumberofFloors','NumberofBuildings')])

train_y = train$SiteEnergyUseWN.kBtu.

# Define Predictor and Response Variables in Testing Set :

test_x = data.matrix(test[, c('GHGEmissionsIntensityPerFloor', 'TotalGHGEmissionsPerFloor', 'EnergyUsePerBuilding', 'EnergyUsePerFloor', 'GFAPerFloor', 'GFAPerBuilding', 'GHGEmissionsIntensity','TotalGHGEmissions','ThirdLargestPropertyUseTypeGFA','SecondLargestPropertyUseTypeGFA','LargestPropertyUseTypeGFA',
                              'NaturalGas.kBtu.','NaturalGas.therms.','Electricity.kBtu.','Electricity.kWh.','PropertyGFABuilding.s.','PropertyGFAParking','PropertyGFATotal','NumberofFloors','NumberofBuildings')])

test_y = test$SiteEnergyUseWN.kBtu.

# Replace Inf and NaN by 0 :

train_x[is.infinite(train_x)] <- 0
train_x[is.na(train_x)] <- 0
train_y[is.infinite(train_y)] <- 0
train_y[is.na(train_y)] <- 0

test_x[is.infinite(test_x)] <- 0
test_x[is.na(test_x)] <- 0
test_y[is.infinite(test_y)] <- 0
test_y[is.na(test_y)] <- 0

# Define Final Training and Testing Sets :

xgb_train = xgb.DMatrix(data = train_x, label = train_y)

xgb_test = xgb.DMatrix(data = test_x, label = test_y)

# Define Watchlist :

watchlist = list(train=xgb_train, test=xgb_test)

# Fit XGBoost Model and display Training and Testing Data at each round :

model = xgb.train(data = xgb_train, max.depth = 3, watchlist=watchlist, nrounds = 100)

# Define Final Model :

model_xgboost = xgboost(data = xgb_train, max.depth = 3, nrounds = 86, verbose = 0)

# Use Model to make Predictions on Test Data :

pred_y = predict(model_xgboost, xgb_test)

# Metrics :

# MSE :

mean((test_y - pred_y)^2) 

# MAE :

caret::MAE(test_y, pred_y) 

# RMSE :

caret::RMSE(test_y, pred_y) %>% knitr::kable()

#### Appendix ####

print("Operating System:")
version
